# predictim claims its ai can flag risky babysitters so 1830913997

> 原文:[https://gizmodo . com/predict im-claims-its-ai-can-flag-risky-保姆-so-1830913997](https://gizmodo.com/predictim-claims-its-ai-can-flag-risky-babysitters-so-1830913997)

Predictim 的创始人想跟我说清楚:他们的产品——一种扫描潜在保姆的在线足迹以确定他们对父母的“风险”水平的算法——不是种族主义。不偏不倚。

“我们非常重视道德和偏见，”Predictim 的首席执行官萨尔·帕萨(Sal Parsa)在电话中小心翼翼地告诉我。“事实上，在过去的 18 个月里，我们训练了我们的产品、我们的机器、我们的算法，以确保它是合乎道德的，没有偏见。我们把敏感的属性，受保护的职业，性别，种族，从我们的训练集中去掉。我们持续审计我们的模型。在的基础上，我们增加了一个人工审核流程。”

<label class="bxm4mm-13 juykRM">Advertisement</label>

有争议的是，我已经用 Predictim 扫描了几个我非常信任的人。我们真正的保姆齐亚·斯托弗(Kianah Stover)对我看来无伤大雅的 Twitter 笑话的“不尊重”评级为“中度风险”(3/5)。她返回的排名比我测试过的一个朋友还要差，事实上，这个朋友经常说脏话。她是黑人，他是白人。

Predictim 的首席技术官乔尔·西蒙诺夫说:“我只是想澄清一下，并不是因为基亚娜是非洲裔美国人才被标记出来的。”。“我可以百分之百地向你保证，那些被标记的帖子没有偏见。我们不看肤色，不看种族，这些甚至都不是算法输入。我们没有办法把它输入算法本身。”

我告诉他们，我确信他们的程序仪表板上没有“反对种族主义”按钮，但我想知道系统性偏见是否会进入他们的数据集中。Parsa 说，“我完全同意它并不完美，它可能有偏见，它可能会标记那些不应该标记的东西，这就是为什么我们增加了人工审查。”但是《人类评论》让这些结果保持不变。

“我认为，”西蒙诺夫说，“这些帖子有迹象表明，某些地方的某些人可能会解释为不尊重。”

<label class="bxm4mm-13 juykRM">Advertisement</label>

* * *

Predictim 宣传了一项服务，承诺通过扫描潜在保姆在社交媒体、网络和在线犯罪数据库中的存在来审查他们。通过使用机器学习——文本的神经语言处理和图像的计算机视觉——来快速筛选一个人一生的图像和帖子， Predictim 据称能够标记出有虐待行为、吸毒和发布露骨图像倾向的个人。你可能不会把孩子托付给他们。

最近，一篇关于这项服务的 [《华盛顿邮报》](https://www.washingtonpost.com/technology/2018/11/16/wanted-perfect-babysitter-must-pass-ai-scan-respect-attitude/?utm_term=.7348f8350b00)*文章在狂热和厌恶的浪潮推动下迅速传播。有人认为，正在部署一种私人算法来分析青少年和低收入工人在社交媒体上的思考和自拍，确定他们的“风险水平”，并将结果提供给容易激动的父母，这在许多人看来是非正式劳动力未来的一个可怕预兆。* 

*“这种 AI sitter 筛选容易出错，基于破碎的假设，侵犯隐私，”NYU AI Now 研究所的创始人凯特·克劳福德在帖子故事撤销后发推文**。“更糟糕的是，这是雇主和求职者之间权力日益不对称的可怕症状。低薪工人不能选择退出。”*** 

***当然，该产品的推出正值对机器学习偏见的审查快速增长之际——最近，亚马逊的一个自动招聘工具被废弃，因为它被确定为对女性 有偏见。自动化系统的缺陷引发了人们的警觉，这些缺陷导致了雇佣和 [解雇工人](https://idiallo.com/blog/when-a-machine-fired-me) 。Predictim 的创始人自己表示，零工是经济中增长最快的部分之一，并暗示他们计划更广泛地提供对合同工的扫描。*** 

***<label class="bxm4mm-13 juykRM">Advertisement</label>***

***所以，我决定带着 Predictim 兜一圈，看看自动化背景调查的美好未来会给带来什么。***

* * *

***进入 Predictim 的 [网站](https://www.predictim.com) ，点击“启动新扫描”，你会被带到一个页面，在那里，一位快乐的白人母亲和她的矮胖婴儿凝视着一台笔记本电脑。上面的文字写着，“购买更多的扫描。你离确保你的家人幸福和安全只有一步之遥了。”只要 24.99 美元，你就可以扫描一个人，前提是你知道他或她的全名、居住城市和电子邮件地址。49.99 美元可以买三张(即买两张扫描，送一张)。***

***当我在系统中输入第一个我打算扫描的人时， Predictim 返回了大量的个人数据——家庭住址、亲戚的名字、电话号码、备用电子邮件地址、作品。当我把他扫描的截图发给我儿子的教父时，他回复道:“哇。”***

***<label class="bxm4mm-13 juykRM">Advertisement</label>***

***目的是让父母在进行扫描之前确保他们找到了合适的人，但这是一个可怕的大量数据。*** 

***“最初，”Parsa 说，“我们允许父母输入潜在保姆的名字，然后它会触发一封电子邮件给他们，他们会选择加入并让我们访问他们的社交媒体档案，然后我们会扫描并生成一份报告，双方都可以看到这份报告。问题是，当很多家长告诉我们，他们不放心告诉保姆，“让我访问你的社交媒体，或者让我扫描你或者在互联网上查看你。”所以我们决定把注意力放在保姆身上。这不需要选择加入或者许可。”(Parsa 还表示，他们正在转向一种仅使用图像来让父母识别保姆的系统。)*** 

***总之，我扫描了我的妻子，我儿子的祖母，他的教父，两个朋友，我们的保姆，还有 Sal Parsa，Predictim 的首席执行官。他向我证实，列出的地址是他现在和以前的居住地，我现在有他的两个电话号码，唯一不正确的数据是一些他不认识的亲戚的名字。*** 

***“你看到的所有信息都是准确的，”他告诉我。我问他是否希望我在文章中发表这些信息。“是的，这是一个非常好的观点:是的，它可以在互联网上获得，但你不想让它变得容易或太容易获得。”*** 

***<label class="bxm4mm-13 juykRM">Advertisement</label>***

* * *

***确认个人详细信息并启动扫描后，该过程可能需要 48 小时。您将收到一封电子邮件，其中包含您的个性化仪表板的链接，该仪表板包含您扫描的所有人及其风险排名，完成后。对于那些不幸熟悉这种地狱般服务的人来说，这个仪表板看起来有点像内容管理系统或网站分析服务 Chartbeat 的后端。***

***左侧是已扫描配置文件的列表；右中间是风险指示器，一个半圆色轮，带有一个指向风险级别的箭头。绿色的风险很低，红色的风险很高。***

***Simonoff 说 Predicitm “并不特别关注单词或短语。我们看上下文。我们称之为将帖子中的单词矢量化为代表其上下文的向量。然后我们有所谓的卷积神经网络，它处理分类。所以我们可以说，这个帖子是攻击性的，是辱骂性的，是礼貌的，是积极的，还是消极的？然后，基于这些输出，我们在它的基础上有几个其他的模型，这些模型提供了风险等级和可解释性。”(他和 Parsa 坚持认为，该系统是在开源和专有数据的结合上进行训练的，但他们拒绝透露数据的来源。)*** 

***<label class="bxm4mm-13 juykRM">Advertisement</label>***

***潜在的保姆按照 1-5 的等级(5 是最危险的)分为四类:“欺凌/骚扰”、“不尊重的态度”、“露骨的内容”和“吸毒”***

***我的妻子和我儿子的祖母，除了偶尔被激怒的政治职位之外，都有非常干净的档案——他们都在大学工作，在那里他们与研究对象和学生互动，并且都是白人——在四个类别中的每一个类别中都获得了“最低风险”的评级。Kianah 是一名 [音乐家](https://open.spotify.com/artist/7BSrECXZBKsvTZFwwIcsux?si=SY0Zg098T1WTtcXGScH-Ug) ，他兼职照看孩子，除了善良和尊重之外，从来没有别的，朋友们热情地向我们推荐他，他被标记为“不尊重态度”的“中度风险”(3/5)，以及“欺凌/骚扰”的“低风险”(2/5)***

***她的总分是“低风险”(5 分中的 2 分)。理论上，这可能看起来没那么糟糕——但是根据在**文章中采访的妈妈们的说法，任何不完美的事情都足以让客户在雇佣保姆时三思。换句话说，如果 Predictim 被广泛采用，这可能会对我们的保姆行业造成重大打击。*****

*****<label class="bxm4mm-13 juykRM">Advertisement</label>*****

*****事实上，当 Predictim 宣布我儿子的教父尼克·卢瑟福(Nick Rutherford)无罪时，最大的惊喜来了，给了他一个接近完美的分数(他在不尊重他人的态度上只得到 2 分，在所有其他方面都得了最高分，总体来说“风险很低”)。卢瑟福是一名专业的漫画和电视作家，他的 Twitter 上充满了粗俗的笑话、性暗示和 F-boys。我花了大约 45 秒找到了半打，自己浏览了他的信息。***** 

*****问题是——为什么齐亚比尼克更危险？***** 

*****Predictim 的创始人指出，当他们的算法确定一个人在任何类别上都被注册为中度风险(5 分之 3)或以上时，它会自动让他们接受人工审查。然后，Predictim 向用户展示被标记的帖子，以便家长可以自己查看这些帖子。我们的保姆在不尊重态度上得分最低，所以我查看了标记的帖子，所有这些帖子都来自她的 Twitter 账户(我应该提到的是，这个账户是匿名的，所以任何搜索他们保姆的孩子都不会找到它)。几样:***** 

*****<label class="bxm4mm-13 juykRM">Advertisement</label>*****

*****“我没有化妆，但我有便便后的红晕，”***** 

*****“我们的法律体系是一个他妈的疯狂的地图。”*****

*****“还没决定我是靛蓝小孩还是自恋狂”*****

*****“2018 年是我停止胡说八道的一年”*****

*****<label class="bxm4mm-13 juykRM">Advertisement</label>*****

*****该系统还标记了转发，因此它收到了一些帖子，如:“RT: 1 我喜欢自己的一点是，我从来没有对 Grey 的解剖感兴趣”，以及“我希望我今天能以一个人的身份出现，并把他妈的活揍一顿”。***** 

*****这就是……基本上是它的要点。这种不尊重的目标是一部电视剧，我们的法律体系，以及某人糟糕的一天。为此，她被打上了不敬的中度风险。***** 

*****同时，这里有一些尼克的帖子:*****

*****“没开玩笑。我看到汤姆·布拉迪吸了 16 次 [@VP](https://twitter.com/VP) 。”*****

*****<label class="bxm4mm-13 juykRM">Advertisement</label>*****

*****"刚刚看到一辆军绿色 PT 巡洋舰，所以你他妈的认为我在做什么."*****

*****“忘了假新闻 ol '胖他妈的在推，今晚看[@企业](https://twitter.com/corporate) 和[@独处](https://twitter.com/AloneTogether)……”*****

*****" '在这一天，我们庆祝新的盖世太保，总统特和他的懦夫军队"-保罗·瑞安"*****

*****这还不包括 RTs。如果有什么不同的话，尼克的帖子更不尊重人，因为它们是针对真实的人和公众人物的——然而尼克以较低的分数顺利通过了。*****

*****<label class="bxm4mm-13 juykRM">Advertisement</label>*****

* * *

*****萨尔·帕萨和乔尔·西蒙诺夫在加州大学伯克利分校相遇，帕萨在那里攻读 MBA，西蒙诺夫在 T2 从事自然语言处理。他们的第一个项目叫做社交过滤器，旨在让求职者找到并删除雇主可能会觉得冒犯的社交媒体帖子。他们把他们的技术带到了伯克利的 SkyDeck 孵化器，在那里他们获得了 10 万美元来发展他们的想法。一路走来，他们抛弃了社会过滤，取而代之的是预测。*****

*****“有一天，在与几位母亲交谈时，我们意识到虐待儿童在西方世界是一个巨大的问题，尤其是在美国，”Parsa 在一封电子邮件中告诉我。帕萨说:“我们开始采访各种类型的人，在这个过程中，我们意识到对我们的技术影响最大、需求最大的是儿童保育和临时保姆。”。他预测，共享经济发展如此之快，10 年后将占全球 GDP 的一半。“然而，还缺少一些东西。”我们仍然依赖“过时的”背景调查。“但在这两者之间没有我们称之为人类信任的东西，”他说。“如果有人来到我家，或者正在照顾我生命中最重要的人，”他继续说道，“我对那个人一无所知，只知道背景调查可能没有问题，也许我在电话里采访过他们——但也许他们展现了最好的自己。然而，有更多的信息可以显示人们真实的性格。”*****

*****帕萨和西蒙诺夫都没有孩子，尽管帕萨已经结婚了，他们都坚持说他们热衷于保护家庭免受坏保姆的伤害。例如，乔尔曾经有一个保姆，她会开车带着他和他的兄弟在车里抽烟。帕萨指着乔尔祖父的看护人。“乔尔的祖父，他有一个人来照顾他——这是一种老年人的照顾——我们对那个人的所有了解是，是的，他没有做过——或者他没有被发现犯罪。”*****

*****根据 Parsa 的说法，该公司目前有 1000 名活跃用户，并获得了一定程度的种子资金，但他拒绝告诉我有多少，或谁投资了。*****

*****<label class="bxm4mm-13 juykRM">Advertisement</label>*****

*****他强调说，预测是为妈妈们量身定做的 T2。“我们采访了 100 位母亲、看护者和宠物主人，”他说。“当我们向他们解释他们的产品时，他们很喜欢。他们说他们每次都会用。”这四个类别是根据来自 T4 研讨会的反馈以及帕萨发给妈咪博客的调查确定的。他们显然注意到了的结果，并为这个众所周知的高度紧张的群体定制了他们的产品。在网站上，有一些标题为“孩子会模仿他们的儿童看护者——你希望你的孩子像谁？”像“保证孩子安全的最好方法是通过社交媒体检查器对看护者进行评估……如果你想让你的孩子模仿那些你会为之骄傲的人，那么你需要 Predictim ”*****

*****因此, Predictim 就是建立在妈妈博客的期望之上的，如果它成功了，未来的保姆们必须不辜负它。*****

* * *

*****“黑人女性受到了过度的惩罚——这可能是因为算法学会了将与黑人个体相关的言论类型联系起来，即使这些言论并没有不尊重人，”克里斯蒂安·卢姆告诉我。Lum 博士是人权数据分析小组的首席统计学家，他已经在著名的《自然》 杂志上发表了论文，并得出结论说，“用编码人类偏见的数据训练的机器学习算法将会重现，而不是消除偏见。”***** 

*****Lum 说她并不特别熟悉 Predictim 的系统，所以对她的评论持保留态度。但基本上，像 Predictim 这样的系统只和它被训练的数据一样好，而这些系统经常充满偏见。*****

*****<label class="bxm4mm-13 juykRM">Advertisement</label>*****

*****“很明显，我们在处理这些结果的方式上缺乏一些背景，”Lum 说，“这是最好的情况。最糟糕的情况是，它被人类贴上了不尊重黑人的标签，并被传递到算法中。”*****

*****公平地说，我扫描了我的另一个黑人朋友——他的帖子可能是我的帖子中最积极、最没有争议的——他被评为风险最低。(如果他不是，那就是克里斯托说*是*种族主义者。)*****

****Parsa 是阿富汗人，他说他自己经历了一生的种族歧视，他甚至把自己的名字从一个更明显的穆斯林名字改成了穆斯林名字，因为尽管他成绩优秀，拥有大学学位，但他无法让未来的雇主回他的电话。换句话说，他对种族主义很敏感，并说他努力确保 Predictim 不被歧视。Parsa 和 Simonoff 坚持认为，他们的系统虽然不完美，但可以发现细微差别并避免偏见。****

****“我们确保训练我们的人工智能模型完全合乎道德，没有偏见，”Parsa 说。“我们确保我们的程序，我们的软件，我们的机器，正如人们所说的，能够理解讽刺或笑话。****

****<label class="bxm4mm-13 juykRM">Advertisement</label>****

* * *

****“它不明白我的讽刺，”齐亚发短信给我。到目前为止，，我已经告诉了她这个故事，并与她分享了 Predictim 标记的帖子。“Lol 好奇怪。我想知道这是否会成为未来工作筛选的一大部分。”**** 

****她说，她并不惊讶她的社交媒体账户会被负面解读，或者这种偏见可能会影响这样一个项目。“我认为系统和它们的创造者一样有偏见，”她写道。尽管如此，她还是不高兴。**** 

****“这让我深感不安，让我感觉自己被放在显微镜下，”她说，并敦促我分享她在故事中的角色。"它有可能创造一个更加充满敌意的世界."**** 

****不仅如此，如果人们真的接受这个系统，这将意味着她可能很难找到工作 Twitter 上几乎所有使用粗俗语言或正常主流之外的方言的人也可能很难找到工作。**** 

****<label class="bxm4mm-13 juykRM">Advertisement</label>****

****“这当然令人担忧，”卢姆博士说。“我们最不希望看到的是，基于对种族和历史偏见进行编码的数据，人们的就业机会越来越少。”(再次说明，她还没有看到这个特定的数据集。)****

****Parsa 和 Simonoff 可能相信他们的使命，也可能不相信，尽管 Parsa 告诉我用谷歌搜索保姆虐待的案例，阅读这些案例几乎让他哭了。(确实有几页充斥着令人毛骨悚然的虐待和忽视的故事，但是，从长远来看，由新罕布什尔大学反儿童犯罪研究中心的教授编写的 2001 年美国司法部公报 指出，保姆只占针对儿童犯罪的 4%，这个数字低于完全陌生人的比率。)****

****但我觉得很有趣的是，他们从帮助求职者剔除和删除冒犯性的帖子转向帮助妈妈和管理员找到那些冒犯性的帖子，然后用它们作为不雇佣人的 T2 理由。对我来说，这就像是一个寻求解决问题的技术案例，也许是一个不受监管的劳动力市场。事实上，在我玩这个网站的几天后，仪表盘上突然出现了一个警告:****

****“Predictim 原文如此]使用公开可用的数据来帮助父母决定他们想要信任谁。 Predictim 不提供私人调查员服务或消费者报告，也不是《公平信用报告法》规定的消费者报告机构。您不得使用我们的网站或服务或所提供的信息来决定雇佣、入住、消费信贷、保险、租户筛选或任何其他需要 FCRA 合规的目的。”****

****<label class="bxm4mm-13 juykRM">Advertisement</label>****

****在一个糟糕的新闻周期中，预测似乎正在掩盖它的基础。在招聘过程中对潜在雇员进行背景调查是非法的，除非他们遵守 FCRA——雇主必须通知潜在雇员他们正在进行调查，并给他们一个质疑结果的机会，同时提供其他保护。然而，这些保护措施并不一定适用于保姆等非正式员工和合同工，这也是 Parsa 和 Simonoff 瞄准这一细分市场的原因之一。(这很像优步和 Lyft 辩称他们的司机是承包商，而不是员工，这让他们可以提供更少的福利，绕开员工保护。)新的警告文本可能是一项旨在给 Predictim 合法掩护的措施，以免雇主非法使用该服务雇佣潜在员工。****

****脸书和推特也对媒体的风波、做出回应，宣布他们 [关闭 Predictim 对他们平台](https://www.bbc.com/news/technology-46354276) 的访问。然而，Simonoff 说他们没有使用任何一方的 API，只是使用公共数据，封锁实际上毫无意义。****

* * *

****目前，西蒙诺夫和帕萨并没有被吓倒。他们说媒体完全误解了他们。“在最近的新闻中，我们受到了媒体的不公平对待，”Parsa 说。“我的意思是，我们对媒体非常专业，因为我们信任和尊重记者。但他们中的一些人歪曲了我们的话。”****

****他们一遍又一遍地强调这一点，即预测已经被错误地贴上了“黑匣子”的标签，这个黑匣子会吐出预测。“我们的产品不能预测一个人是好保姆还是坏保姆，”Parsa 说。“我们不是干这个的。”我没有指出公司的名字是字面上的*预测*即时消息。创始人坚持认为，这一切都是为了让父母掌握更多数据，帮助父母做出更明智的决定，让每个人都更安全。但是这些结果，现在，充其量是不可靠和不一致的。一旦这些系统开始闪烁中度及以上风险的警告，普通用户*就会*偏向于结果，不管引擎盖后面是什么样的人工智能或人工审查。****

****<label class="bxm4mm-13 juykRM">Advertisement</label>****

****Lum 说:“在我们获得无偏见的训练数据之前，我们还不能作为一个社会来决定一个人对人工智能的尊重程度。”****

****不管准备好了没有，自动化评估工具的使用只会越来越多。我们已经不得不与雇主和信用机构竞争，通过梳理过去的帖子来得出关于可雇佣性、贷款价值、甚至医疗保健资格的结论。这些过程的自动化使它们变得更加不可思议，也更难被受影响的各方质疑；算法错误一端的 gig 工人。****

****Predictim 可能是一个避雷针，因为他们在扫描一个特别敏感的群体时做得过火了——我反复问创始人，他们是否想生活在一个朋友之间的临时职位可以决定就业资格的世界里，甚至在十几岁的保姆中间，他们表示反对，或谈到父母了解保姆一切的“绝对权利”。但硅谷投资者支持此类风险投资的需求和意愿，预示着未来将充满类似的、或许更精明的创业公司。而且可能不会是那些被算法评分的人来决定如何以及何时推出它。**** 

****“我们正在逐步发布我们的技术，”Simonoff 说。"这是漫长过程中的第一步。"**** 

****<label class="bxm4mm-13 juykRM">Advertisement</label>****

* * *

*****这个故事是* [*自动机*](https://gizmodo.com/introducing-automaton-1830912297) *的一部分，这是一项正在进行的关于人工智能和自动化对人类景观影响的调查。关于与机器人相处的提示、反馈或其他想法，可以在 bmerchant@gizmodo.com 找到我。*****